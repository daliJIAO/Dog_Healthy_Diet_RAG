import gradio as gr
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.llms import Ollama
from langchain.chains import RetrievalQA

# åˆå§‹åŒ–å¯¹è¯å†å²
conversation_history = []
DEFAULT_HISTORY_LENGTH = 5

def create_qa_chain(model_name, embedding_model_name, k, nprobe, ef_search):
    embedding = HuggingFaceEmbeddings(model_name=embedding_model_name)
    db = FAISS.load_local("vectorstore", embedding, allow_dangerous_deserialization=True)

    # è®¾ç½®æ£€ç´¢å™¨
    retriever = db.as_retriever(
        search_kwargs={"k": int(k), "nprobe": int(nprobe), "efSearch": int(ef_search)}
    )
    llm = Ollama(model=model_name)

    return RetrievalQA.from_chain_type(
        llm=llm,
        retriever=retriever,
        return_source_documents=True
    )

def answer_query(query, history_length, embedding_model_name, base_model_name, k, nprobe, ef_search):
    global conversation_history

    # é™åˆ¶å†å²é•¿åº¦
    if len(conversation_history) > history_length * 2:
        conversation_history = conversation_history[-history_length * 2:]

    conversation_history.append(f"ç”¨æˆ·: {query}")
    qa_chain = create_qa_chain(base_model_name, embedding_model_name, k, nprobe, ef_search)
    full_context = "\n".join(conversation_history)
    result = qa_chain.invoke(full_context)

    conversation_history.append(f"æ¨¡å‹: {result['result']}")

    sources = [
        f"{i + 1}. æ–‡ä»¶å: {doc.metadata.get('source', 'æœªçŸ¥')} | å†…å®¹ç‰‡æ®µ: {doc.page_content[:60]}..."
        for i, doc in enumerate(result["source_documents"])
    ]
    return result['result'], sources, ""

def clear_history():
    global conversation_history
    conversation_history.clear()
    return "", "", "âœ… å¯¹è¯å†å²å·²æ¸…é™¤"

def gradio_interface():
    model_options = ["deepseek-r1:7b", "llama3"]
    embedding_options = ["all-MiniLM-L6-v2", "text2vec-base-chinese"]

    with gr.Blocks() as demo:
        gr.Markdown("## ğŸ§ª RAG é—®ç­”ç³»ç»Ÿ Â· æ£€ç´¢å‚æ•°è°ƒèŠ‚é¢æ¿")

        with gr.Column():
            query_input = gr.Textbox(label="ğŸ§  è¯·è¾“å…¥ä½ çš„é—®é¢˜", placeholder="ä¾‹å¦‚ï¼šå¦‚ä½•ä¸ºè¨æ‘©è€¶å®šåˆ¶è¥å…»é£Ÿè°±ï¼Ÿ")
            result_output = gr.Textbox(label="ğŸ¤– æ¨¡å‹å›ç­”", lines=4)
            source_output = gr.JSON(label="ğŸ“š ç›¸å…³æ–‡æ¡£")
            status_output = gr.Textbox(label="âš ï¸ ç³»ç»ŸçŠ¶æ€/æç¤º", interactive=False)

        with gr.Row():
            history_input = gr.Number(label="ğŸ•— é™åˆ¶å¯¹è¯å†å²è½®æ•°", value=DEFAULT_HISTORY_LENGTH, precision=0,
                                      info="å»ºè®®è®¾ç½®ä¸º5ï¼Œå¯æ§åˆ¶ä¸Šä¸‹æ–‡é•¿åº¦")
            embedding_dropdown = gr.Dropdown(choices=embedding_options, label="ğŸ“Œ é€‰æ‹©è¯åµŒå…¥æ¨¡å‹",
                                             value="all-MiniLM-L6-v2", info="éœ€ä¸ ingest.py ä¸­æ¨¡å‹ä¸€è‡´")
            base_model_dropdown = gr.Dropdown(choices=model_options, label="ğŸ“¦ é€‰æ‹©åŸºåº•å¤§æ¨¡å‹", value="deepseek-r1:7b")

        with gr.Row():
            k_slider = gr.Slider(1, 10, value=3, step=1, label="ğŸ” kï¼ˆè¿”å›å‰kä¸ªæ–‡æ¡£ï¼‰",
                                 info="è¶Šå¤§ç»“æœè¶Šå…¨ï¼Œå“åº”æ—¶é—´ä¹Ÿæ›´ä¹…")
            nprobe_slider = gr.Slider(1, 50, value=10, step=1, label="âš™ï¸ nprobeï¼ˆæœç´¢ç°‡æ•°é‡ï¼‰",
                                      info="é€‚ç”¨äº IVF ç´¢å¼•ï¼Œæé«˜å¬å›ç‡")
            ef_slider = gr.Slider(10, 100, value=40, step=1, label="ğŸ“ˆ efSearchï¼ˆHNSW æœç´¢å¹¿åº¦ï¼‰",
                                  info="é€‚ç”¨äº HNSW ç´¢å¼•ï¼Œæé«˜å‡†ç¡®ç‡")

        with gr.Row():
            submit_btn = gr.Button("ğŸš€ æäº¤æé—®")
            clear_btn = gr.Button("ğŸ§¹ æ¸…é™¤å†å²")

        # äº‹ä»¶ç»‘å®š
        submit_btn.click(
            fn=answer_query,
            inputs=[query_input, history_input, embedding_dropdown, base_model_dropdown,
                    k_slider, nprobe_slider, ef_slider],
            outputs=[result_output, source_output, status_output]
        )
        clear_btn.click(fn=clear_history, inputs=[], outputs=[result_output, source_output, status_output])

    return demo

# å¯åŠ¨ Gradio åº”ç”¨
if __name__ == "__main__":
    gradio_interface().launch()
